{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import codecs\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import tensorflow as tf\n",
    "import cPickle as pickle\n",
    "import scipy.sparse as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "from tensorflow.contrib.layers import safe_embedding_lookup_sparse\n",
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple, GRUCell\n",
    "\n",
    "from src.helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_A_PATH, CORPUS_B_PATH = './corpora/europarl.de-en.en', './corpora/europarl.de-en.de'\n",
    "# CORPUS_A_PATH, CORPUS_B_PATH = './corpora/europarl.pl-en.pl', './corpora/europarl.pl-en.en'\n",
    "\n",
    "# LOAD CORPUS\n",
    "corpus_a, vocab_cnt_a = load_corpus(CORPUS_A_PATH)\n",
    "corpus_b, vocab_cnt_b = load_corpus(CORPUS_B_PATH)\n",
    "\n",
    "raw_corpus_a_size = sum(vocab_cnt_a.itervalues())\n",
    "raw_vocab_a_size = len(vocab_cnt_a)\n",
    "raw_corpus_b_size = sum(vocab_cnt_b.itervalues())\n",
    "raw_vocab_b_size = len(vocab_cnt_b)\n",
    "\n",
    "print 'Corpus A size (total tokens):', raw_corpus_a_size\n",
    "print 'Corpus A vocabulary size (distinct tokens):', raw_vocab_a_size\n",
    "print 'Most popular words (corpus A):', vocab_cnt_a.most_common(5)\n",
    "print\n",
    "print 'Corpus B size (total tokens):', raw_corpus_b_size\n",
    "print 'Corpus B vocabulary size (distinct tokens):', raw_vocab_b_size\n",
    "print 'Most popular words (corpus B):', vocab_cnt_b.most_common(5)\n",
    "\n",
    "# visualize distribution\n",
    "counts_a = sorted(vocab_cnt_a.itervalues(), reverse=True)\n",
    "counts_b = sorted(vocab_cnt_b.itervalues(), reverse=True)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)\n",
    "plt.semilogy(range(len(counts_a)), counts_a)\n",
    "plt.title('Distribution of token occurences (Corpus SRC)')\n",
    "plt.xlabel('Token')\n",
    "plt.ylabel('Occurences')\n",
    "plt.grid()\n",
    "plt.subplot(122)\n",
    "plt.semilogy(range(len(counts_b)), counts_b)\n",
    "plt.title('Distribution of token occurences (Corpus TRG)')\n",
    "plt.xlabel('Token')\n",
    "plt.ylabel('Occurences')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LIMIT VOCABS\n",
    "LANG_A_TOKEN_LIMIT = 25000\n",
    "vocab_a, vocab_enc_a, vocab_dec_a = code_tokens(vocab_cnt_a, LANG_A_TOKEN_LIMIT)\n",
    "# corpus_a_enc = [[vocab_enc_a[word] for word in sentence if word in vocab_enc_a] for sentence in corpus_a]\n",
    "\n",
    "LANG_B_TOKEN_LIMIT = 35000\n",
    "vocab_b, vocab_enc_b, vocab_dec_b = code_tokens(vocab_cnt_b, LANG_B_TOKEN_LIMIT)\n",
    "# corpus_b_enc = [[vocab_enc_b[word] for word in sentence if word in vocab_enc_b] for sentence in corpus_b]\n",
    "del corpus_a\n",
    "del corpus_b\n",
    "\n",
    "# print 'Clean corpus A size (total sentences):', len(corpus_a_enc)\n",
    "# print 'Clean corpus A vocabulary size (distinct tokens):', len(vocab_a)\n",
    "# print\n",
    "# print 'Clean corpus B size (total sentences):', len(corpus_b_enc)\n",
    "# print 'Clean corpus B vocabulary size (distinct tokens):', len(vocab_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_par = zip(corpus_a_enc, corpus_b_enc)\n",
    "length_diff = Counter([abs(len(a) - len(b)) for a, b in corpus_par])\n",
    "\n",
    "print 'Max length diff:', max(length_diff.keys())\n",
    "print 'Avg length diff:', sum(length_diff.keys()) / len(corpus_par)\n",
    "\n",
    "keys, values = zip(*sorted(length_diff.iteritems(), key=lambda x: x[0]))\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.semilogy(keys, values)\n",
    "plt.title('Distribution of length differences (Corpus Parallel)')\n",
    "plt.xlabel('Length Difference')\n",
    "plt.ylabel('Occurences')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnSeqToSeq(object):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, emb_size=100, enc_units=100, dec_units=100, \n",
    "                 num_layers=1, attn_span=25, bi_dir=False, learning_rate=1e-3, pad_token=0, eos_token=2):\n",
    "        self.src_vocab_size = src_vocab_size\n",
    "        self.trg_vocab_size = trg_vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        self.enc_units = enc_units\n",
    "        self.dec_units = dec_units\n",
    "        self.num_layers = num_layers\n",
    "        self.attn_span = attn_span\n",
    "        self.bi_dir = bi_dir\n",
    "        self.learning_rate = learning_rate\n",
    "        self.pad_token = pad_token\n",
    "        self.eos_token = eos_token\n",
    "        \n",
    "        self._build_model()\n",
    "        \n",
    "    def _init_placeholders(self):\n",
    "        with tf.variable_scope('placeholders') as scope:\n",
    "            self.enc_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "            self.dec_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\n",
    "            self.dec_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "\n",
    "            self.enc_inputs_len = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_len')\n",
    "            self.dec_inputs_len = tf.placeholder(shape=(None,), dtype=tf.int32, name='decoder_inputs_len')\n",
    "            self.max_dec_inputs_len = tf.reduce_max(self.dec_inputs_len, name='max_decoder_inputs_len')\n",
    "            \n",
    "            self.batch_size = tf.shape(self.enc_inputs)[0]\n",
    "            self.avg_eval_loss = tf.placeholder_with_default(0.0, shape=None, name='avg_eval_loss')\n",
    "            \n",
    "    def _init_variables(self):\n",
    "        # define global variables\n",
    "        self.global_step = tf.Variable(\n",
    "            initial_value=0, \n",
    "            trainable=False, \n",
    "            name='global_step')\n",
    "        \n",
    "        # define embeddings and lookup\n",
    "        with tf.variable_scope('embeddings') as scope:\n",
    "            self.embeddings_src = tf.Variable(\n",
    "                tf.random_uniform([self.src_vocab_size, self.emb_size], -0.15, 0.15), \n",
    "                dtype=tf.float32,\n",
    "                name='embeddings_src')\n",
    "            self.embeddings_trg = tf.Variable(\n",
    "                tf.random_uniform([self.trg_vocab_size, self.emb_size], -0.15, 0.15), \n",
    "                dtype=tf.float32,\n",
    "                name='embeddings_trg')\n",
    "    \n",
    "    def _init_encoder(self):\n",
    "        with tf.variable_scope('encoder') as scope:\n",
    "            enc_inputs_emb = tf.nn.embedding_lookup(self.embeddings_src, self.enc_inputs)\n",
    "            enc_cell = tf.contrib.rnn.GRUCell(self.enc_units)\n",
    "            self.enc_outputs, self.enc_final_state = tf.nn.dynamic_rnn(\n",
    "                cell=enc_cell, \n",
    "                inputs=enc_inputs_emb, \n",
    "                sequence_length=self.enc_inputs_len, \n",
    "                time_major=False, \n",
    "                dtype=tf.float32, \n",
    "                scope='encoder_cell')\n",
    "            \n",
    "    def _init_decoder(self):\n",
    "        # training decoder\n",
    "        with tf.variable_scope('decoder') as scope:\n",
    "            dec_inputs_emb = tf.nn.embedding_lookup(self.embeddings_trg, self.dec_inputs)\n",
    "            \n",
    "            attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "                num_units=self.dec_units,\n",
    "                memory=self.enc_outputs,\n",
    "                memory_sequence_length=self.enc_inputs_len)\n",
    "            \n",
    "            dec_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell=tf.contrib.rnn.GRUCell(self.dec_units),\n",
    "                attention_mechanism=attention_mechanism,\n",
    "                attention_layer_size=self.dec_units,\n",
    "                output_attention=True,\n",
    "                alignment_history=True,\n",
    "                name='attention_wrapper'\n",
    "                )\n",
    "            \n",
    "            dec_cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "                dec_cell,\n",
    "                self.trg_vocab_size\n",
    "            )\n",
    "\n",
    "            dec_train_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                inputs=dec_inputs_emb,\n",
    "                sequence_length=self.dec_inputs_len,\n",
    "                time_major=False,\n",
    "                name='training_helper')\n",
    "\n",
    "            dec_initial_state = dec_cell.zero_state(batch_size=self.batch_size, dtype=tf.float32).clone(cell_state=self.enc_final_state) \n",
    "            dec_train_decoder = seq2seq.BasicDecoder(\n",
    "                cell=dec_cell,\n",
    "                helper=dec_train_helper,\n",
    "                initial_state=dec_initial_state)\n",
    "\n",
    "            self.dec_train_outputs, dec_train_final_state, _ = seq2seq.dynamic_decode(\n",
    "                decoder=dec_train_decoder,\n",
    "                output_time_major=False,\n",
    "                impute_finished=True,\n",
    "                maximum_iterations=self.max_dec_inputs_len)\n",
    "        \n",
    "            self.train_attn_history = self._prepare_attention_images(\n",
    "                dec_train_final_state.alignment_history)\n",
    "            \n",
    "            # inference decoder\n",
    "            batch_size = tf.shape(self.enc_inputs)[0]\n",
    "            eos_slice = tf.fill([batch_size], self.eos_token, name='EOS')\n",
    "\n",
    "            dec_infer_helper = seq2seq.GreedyEmbeddingHelper(\n",
    "                embedding=self.embeddings_trg,\n",
    "                start_tokens=eos_slice,\n",
    "                end_token=self.eos_token)\n",
    "\n",
    "            dec_infer_decoder = seq2seq.BasicDecoder(\n",
    "                cell=dec_cell,\n",
    "                helper=dec_infer_helper,\n",
    "                initial_state=dec_initial_state)\n",
    "\n",
    "            self.dec_infer_outputs, dec_infer_final_state, _ = seq2seq.dynamic_decode(\n",
    "                decoder=dec_infer_decoder,\n",
    "                output_time_major=False,\n",
    "                impute_finished=True)\n",
    "    \n",
    "            self.infer_attn_history = self._prepare_attention_images(\n",
    "                dec_infer_final_state.alignment_history)\n",
    "    \n",
    "    def _init_optimizer(self):\n",
    "        with tf.variable_scope('optimization') as scope:\n",
    "            dec_train_logits = tf.identity(self.dec_train_outputs.rnn_output)\n",
    "            dec_infer_logits = tf.identity(self.dec_infer_outputs.rnn_output)\n",
    "            self.dec_train_preds = tf.identity(self.dec_train_outputs.sample_id) \n",
    "            self.dec_infer_preds = tf.identity(self.dec_infer_outputs.sample_id)\n",
    "\n",
    "            masks = tf.sequence_mask(\n",
    "                lengths=self.dec_inputs_len, \n",
    "                maxlen=self.max_dec_inputs_len,\n",
    "                dtype=tf.float32, \n",
    "                name='masks')\n",
    "\n",
    "            self.loss = seq2seq.sequence_loss(\n",
    "                logits=dec_train_logits,\n",
    "                targets=self.dec_targets,\n",
    "                weights=masks,\n",
    "                average_across_timesteps=True,\n",
    "                average_across_batch=True)\n",
    "\n",
    "            # setup optimizer and training step\n",
    "            self.opt = tf.train.AdamOptimizer(self.learning_rate)\n",
    "            \n",
    "            trainable_params = tf.trainable_variables()\n",
    "            gradients = tf.gradients(self.loss, trainable_params)\n",
    "            # add gradient clipping\n",
    "            clip_gradients = gradients\n",
    "            self.updates = self.opt.apply_gradients(\n",
    "                zip(clip_gradients, trainable_params), \n",
    "                global_step=self.global_step)\n",
    "    \n",
    "            # summaries\n",
    "            self.train_summary = tf.summary.scalar('train_loss', self.loss)\n",
    "            self.valid_summary = tf.summary.scalar('valid_loss', self.loss)\n",
    "            self.train_attention_summary = tf.summary.image('train_attention_history', self.train_attn_history)\n",
    "            self.infer_attention_summary = tf.summary.image('infer_attention_history', self.infer_attn_history)\n",
    "            self.avg_valid_summary = tf.summary.scalar('avg_valid_loss', self.avg_eval_loss)\n",
    "            \n",
    "    def _build_model(self):\n",
    "        self._init_placeholders()\n",
    "        self._init_variables()\n",
    "        self._init_encoder()\n",
    "        self._init_decoder()\n",
    "        self._init_optimizer()\n",
    "        \n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    def _get_feed_dict(self, enc_in, enc_in_len, dec_in=None, dec_in_len=None, dec_out=None):\n",
    "            feed_dict = { self.enc_inputs: enc_in, self.enc_inputs_len: enc_in_len}\n",
    "            \n",
    "            if dec_in is not None:\n",
    "                feed_dict[self.dec_inputs] = dec_in\n",
    "            if dec_in_len is not None:\n",
    "                feed_dict[self.dec_inputs_len] = dec_in_len\n",
    "            if dec_out is not None:\n",
    "                feed_dict[self.dec_targets] = dec_out\n",
    "                \n",
    "            return feed_dict\n",
    "        \n",
    "    def _prepare_attention_images(self, alignment_history):\n",
    "        attention_images = alignment_history.stack()\n",
    "        attention_images = tf.expand_dims(\n",
    "            tf.transpose(attention_images, [1, 2, 0]), -1)\n",
    "        attention_images *= 255\n",
    "        return attention_images\n",
    "    \n",
    "    def train(self, sess, enc_inputs, enc_inputs_len, dec_inputs, dec_inputs_len, dec_targets):\n",
    "        fd = self._get_feed_dict(enc_inputs, enc_inputs_len, \n",
    "                                 dec_inputs, dec_inputs_len, \n",
    "                                 dec_targets)\n",
    "        \n",
    "        operations = [self.updates, self.loss, self.train_summary, self.enc_final_state]\n",
    "        _, l, sl, e = sess.run(operations, fd)\n",
    "        return l, sl, e\n",
    "    \n",
    "    def evaluate(self, sess, enc_inputs, enc_inputs_len, dec_inputs, dec_inputs_len, dec_targets):\n",
    "        fd = self._get_feed_dict(enc_inputs, enc_inputs_len, \n",
    "                                 dec_inputs, dec_inputs_len, \n",
    "                                 dec_targets)\n",
    "        \n",
    "        operations = [self.loss, self.train_summary, self.train_attn_history, \n",
    "                      self.dec_train_preds, self.enc_final_state]\n",
    "        l, sl, ah, p, e = sess.run(operations, fd)\n",
    "        return l, sl, ah, p, e\n",
    "    \n",
    "    def infer(self, sess, enc_inputs, enc_inputs_len):\n",
    "        fd = self._get_feed_dict(enc_inputs, enc_inputs_len)\n",
    "        return sess.run([self.dec_infer_preds, self.infer_attn_history], fd)\n",
    "    \n",
    "    def encode_seq(self, sess, enc_inputs, enc_inputs_len):\n",
    "        fd = self._get_feed_dict(enc_inputs, enc_inputs_len)\n",
    "        return sess.run([self.enc_final_state], fd)\n",
    "    \n",
    "    def save_model(self, sess, path):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, save_path=path, global_step=self.global_step)\n",
    "    \n",
    "    def restore_model(self, sess, path):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example - Reconstructing Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXPERIMENT PARAMETERS\n",
    "VOCAB_SIZE_SRC = VOCAB_SIZE_TRG = 10\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_DATA_SIZE = 500000\n",
    "VAL_DATA_SIZE = 1000\n",
    "\n",
    "NUM_LAYERS = 1\n",
    "EMB_SIZE = 15\n",
    "ENC_UNITS = DEC_UNITS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "HARD_MAX_LEN = 128\n",
    "\n",
    "SUMM_INTERVAL = 100\n",
    "EVAL_INTERVAL = 25\n",
    "CKPT_INTERVAL = 1000\n",
    "\n",
    "CKPT_PATH = './models/'\n",
    "LOG_PATH = './logs/'\n",
    "EXPERIMENT_NAME = 'toy-example'\n",
    "\n",
    "# EXPERIMENT DATA\n",
    "SEQ_MAX_LEN = 30\n",
    "train_data = toy_data_generator(VOCAB_SIZE_SRC, TRAIN_DATA_SIZE, SEQ_MAX_LEN, 3)\n",
    "eval_data = list(toy_data_generator(VOCAB_SIZE_SRC, VAL_DATA_SIZE, SEQ_MAX_LEN, 3))\n",
    "vocab_dec_a = {ix: str(ix) for ix in xrange(11)}\n",
    "vocab_dec_b = vocab_dec_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Europarl DE-EN Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT PARAMETERS\n",
    "VOCAB_SIZE_SRC = len(vocab_a)\n",
    "VOCAB_SIZE_TRG = len(vocab_b)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "NUM_LAYERS = 1\n",
    "EMB_SIZE = 200\n",
    "ENC_UNITS = 500\n",
    "DEC_UNITS = ENC_UNITS\n",
    "LEARNING_RATE = 0.001\n",
    "HARD_MAX_LEN = 128\n",
    "\n",
    "SUMM_INTERVAL = 100\n",
    "EVAL_INTERVAL = 250\n",
    "CKPT_INTERVAL = 1000\n",
    "\n",
    "CKPT_PATH = './models/'\n",
    "LOG_PATH = './logs/'\n",
    "EXPERIMENT_NAME = 'ep-de'\n",
    "\n",
    "# EXPERIMENT DATA\n",
    "# random.seed(1)\n",
    "# random.shuffle(corpus_par)\n",
    "# corpus_len = len(corpus_par)\n",
    "# train_split, eval_split, test_split = int(0.8*corpus_len), int(0.1*corpus_len), int(0.1*corpus_len)\n",
    "# train_data = corpus_par[:train_split]\n",
    "# eval_data = corpus_par[train_split:train_split+eval_split]\n",
    "# test_data = corpus_par[-test_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = AttnSeqToSeq(VOCAB_SIZE_SRC, VOCAB_SIZE_TRG, EMB_SIZE, ENC_UNITS, DEC_UNITS, \n",
    "                 learning_rate=LEARNING_RATE, attn_span=SEQ_MAX_LEN)\n",
    "\n",
    "try:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    summary_writer = tf.summary.FileWriter(\n",
    "        os.path.join(LOG_PATH, EXPERIMENT_NAME + time.strftime(\"%Y-%m-%d-%H-%M-%S\")),\n",
    "        graph=sess.graph)\n",
    "    \n",
    "    while True:\n",
    "        batches_gen = batchify_data(train_data, BATCH_SIZE)\n",
    "        train_losses = []\n",
    "        for data_batch in batches_gen: \n",
    "            batch_src, batch_trg = zip(*data_batch)\n",
    "#             batch_trg = [row[::-1] for row in batch_trg]\n",
    "            \n",
    "            # prepare batch\n",
    "            enc_inp, enc_lengths = pad_data(batch_src, append_suf=[2])\n",
    "            dec_inp, _ = pad_data(batch_trg, append_pre=[2])\n",
    "            dec_trg, dec_lengths = pad_data(batch_trg, append_suf=[2])\n",
    "            \n",
    "            # training step\n",
    "            if enc_inp.shape[1] > HARD_MAX_LEN: continue\n",
    "            if enc_inp.shape[0] != BATCH_SIZE: continue\n",
    "            l, sl, _ = model.train(sess, enc_inp, enc_lengths, dec_inp, dec_lengths, dec_trg)\n",
    "            train_losses.append(l)\n",
    "            \n",
    "            # summarize, eval, etc.\n",
    "            global_step = model.global_step.eval()\n",
    "            if global_step % CKPT_INTERVAL == 0:\n",
    "                ckpt_file = os.path.join(CKPT_PATH, EXPERIMENT_NAME + time.strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "#                 model.save_model(sess, ckpt_file)\n",
    "                print 'Saved model...'\n",
    "                \n",
    "            if global_step == 1 or global_step % SUMM_INTERVAL == 0:\n",
    "                summary_writer.add_summary(sl, global_step)\n",
    "\n",
    "            if global_step == 1 or global_step % EVAL_INTERVAL == 0:\n",
    "                eval_losses = []\n",
    "                example_input, example_pred, example_attn = None, None, None\n",
    "                for batch_data in batchify_data(eval_data, BATCH_SIZE): \n",
    "                    batch_src, batch_trg = zip(*batch_data)\n",
    "#                     batch_trg = [row[::-1] for row in batch_trg]\n",
    "                    \n",
    "                    enc_inp, enc_lengths = pad_data(batch_src, append_suf=[2])\n",
    "                    dec_inp, _ = pad_data(batch_trg, append_pre=[2])\n",
    "                    dec_trg, dec_lengths = pad_data(batch_trg, append_suf=[2])\n",
    "                    \n",
    "                    if enc_inp.shape[1] > HARD_MAX_LEN: continue\n",
    "                    if enc_inp.shape[0] != BATCH_SIZE: continue\n",
    "                    l, _a, ah, p, _b = model.evaluate(sess, enc_inp, enc_lengths, dec_inp, dec_lengths, dec_trg)\n",
    "                    example_input, example_pred, example_attn = enc_inp, p, ah\n",
    "                    eval_losses.append(l)\n",
    "                    \n",
    "#                 plt.imshow(example_attn[0][:,:,0])\n",
    "#                 plt.savefig('example-attn-step-{}.png'.format(global_step))\n",
    "                print('batch {}'.format(global_step))\n",
    "                print('train losses: {} / eval losses: {}'.format(np.mean(train_losses), np.mean(eval_losses)))\n",
    "                for i, (inp, pred) in enumerate(zip(example_input, example_pred)[:3]):\n",
    "                    print('sample {}:'.format(i + 1))\n",
    "                    print('input     >> {}'.format(' '.join([vocab_dec_a[word].encode('ascii', errors='replace') for word in inp])))\n",
    "                    print('predicted >> {}'.format(' '.join([vocab_dec_b[word].encode('ascii', errors='replace') for word in pred])))\n",
    "                    \n",
    "                eval_s = sess.run(model.avg_valid_summary, {model.avg_eval_loss: np.mean(eval_losses)})\n",
    "                summary_writer.add_summary(eval_s, global_step)\n",
    "                    \n",
    "                # clear train losses\n",
    "                train_losses = []\n",
    "        summary_writer.flush()\n",
    "                    \n",
    "except KeyboardInterrupt:\n",
    "    ckpt_file = os.path.join(CKPT_PATH, EXPERIMENT_NAME + time.strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "#     model.save_model(sess, ckpt_file)\n",
    "    summary_writer.close()\n",
    "    print 'Training Interrupted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_seq = [[3,4,5,6,7,8,9,2]]\n",
    "source_len = [9]\n",
    "target_seq, attn_img = model.infer(sess, source_seq, source_len)\n",
    "plot_alignment(attn_img[0][:,:,0], map(str, source_seq[0])[:source_len[0]], map(str, target_seq[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = SeqToSeq(VOCAB_SIZE_SRC, VOCAB_SIZE_TRG, EMB_SIZE, ENC_UNITS, DEC_UNITS, learning_rate=LEARNING_RATE)\n",
    "model.restore_model(sess, './models/basic/ep-de2017-10-09-17-21-06-11000')\n",
    "# model.restore_model(sess, './models/reversed/ep-de2017-10-10-00-01-03-11000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run inference on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_losses, translations = [], []\n",
    "test_data = corpus_par_small\n",
    "data_batches = list(batchify_data(test_data, BATCH_SIZE))\n",
    "for data_batch in tqdm(data_batches): \n",
    "    batch_src, batch_trg = zip(*data_batch)\n",
    "    enc_inp = [line[::-1] for line in enc_inp]\n",
    "    enc_inp, enc_lengths = pad_data(batch_src, append_suf=[2])\n",
    "    dec_inp, _ = pad_data(batch_trg, append_pre=[2])\n",
    "    dec_trg, dec_lengths = pad_data(batch_trg, append_suf=[2])\n",
    "    if enc_inp.shape[1] > HARD_MAX_LEN: continue\n",
    "    l, _, p, _ = model.evaluate(sess, enc_inp, enc_lengths, dec_inp, dec_lengths, dec_trg)\n",
    "    translations.append(model.infer(sess, enc_inp, enc_lengths))\n",
    "    test_losses.append(l)\n",
    "    \n",
    "# flatten and cleanup network output\n",
    "trans = [trans.tolist() for wrap_batch in translations for batch in wrap_batch for trans in batch]\n",
    "trans_end_ix = [line.index(2) for line in trans]\n",
    "trans_pred = [line[:end_ix] for line, end_ix in zip(trans, trans_end_ix)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute BLEU score and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_words = [[vocab_dec_b[token] for token in line] for line in trans_pred]\n",
    "targ_words = [[vocab_dec_b[token] for token in line[1]] for line in corpus_par_small]\n",
    "bleu.corpus_bleu([[sentence] for sentence in targ_words], pred_words, weights=(0.4,0.3,0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ix in xrange(len(test_data)):\n",
    "    print 'SRC: ', ' '.join([vocab_dec_a[token] for token in test_data[ix][0]])\n",
    "    print 'TARGET: ', ' '.join([vocab_dec_b[token] for token in test_data[ix][1]])\n",
    "    print 'PEDICT: ', ' '.join([vocab_dec_b[token] for token in trans_pred[ix]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save translations to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('test-source.en', 'w', encoding='utf-8') as test_src:\n",
    "    with codecs.open('test-target.de', 'w', encoding='utf-8') as test_trg:\n",
    "        with codecs.open('test-pred.de', 'w', encoding='utf-8') as test_prd:\n",
    "            for ix in xrange(len(test_data)):\n",
    "                test_src.write(' '.join([vocab_dec_a[token] for token in test_data[ix][0]]) + '\\n')\n",
    "                test_trg.write(' '.join([vocab_dec_b[token] for token in test_data[ix][1]]) + '\\n')\n",
    "                test_prd.write(' '.join([vocab_dec_b[token] for token in trans_pred[ix]]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_sentences = [\n",
    "    'the president met with other leaders',\n",
    "    'italian prime minister berlusconi',\n",
    "    'merkel spoke to the president',\n",
    "    'foreign policy was discussed in the meeting',\n",
    "    'summit touching on international affairs',\n",
    "    'debate about the foreign affairs',\n",
    "    'support for developing countries',\n",
    "    'financial aid for the poorest',\n",
    "    'social benefits for the needy',\n",
    "    'handling the immigration crisis',\n",
    "    'refugees seeking asylum'\n",
    "                ]\n",
    "\n",
    "src_sentences = [\n",
    "    'angela merkel', 'barack obama', 'vladimir putin',\n",
    "    'poland', 'hungary', 'slovakia', 'czech',\n",
    "    'norway', 'sweden', 'finland', 'denmark',\n",
    "    'foreign affairs', 'foreign policy', 'international affairs'\n",
    "    \n",
    "]\n",
    "\n",
    "src_split = [sentence.split(' ') for sentence in src_sentences]\n",
    "src_enc = [[vocab_enc_a[word] for word in sent] for sent in src_split]\n",
    "enc_inp, enc_len = pad_data(src_enc, append_suf=[2])\n",
    "\n",
    "encoded = model.encode_seq(sess, enc_inp, enc_len)[0]\n",
    "pca = get_pca_embeddings(encoded)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for point, label in zip(pca, src_sentences):\n",
    "    x, y = point[0], point[1]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(label, xy = (x, y), ha='center',  va='bottom', xytext=(3,2), textcoords='offset points', fontsize=15)\n",
    "plt.grid()\n",
    "plt.savefig('mt-basic-sent-emb.png')\n",
    "plt.show()\n",
    "# for ix in xrange(len(src_sentences)):\n",
    "#     print 'INPUT: ', ' '.join([vocab_dec_a[token] for token in src_enc[ix]])\n",
    "#     print 'OUTPUT:', ' '.join([vocab_dec_b[token].encode('utf8') for token in model.infer(sess, enc_inp, enc_len)[0][ix].tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_split(file_path):\n",
    "    with open(file_path, 'r') as fd:\n",
    "        return [line.split(' ') for line in fd]\n",
    "\n",
    "# load data and store it in tuple (source, target, pred_basic, pred_reverse, pred_gnmt)\n",
    "data_src = load_and_split('other/translations/test-source.en.txt')\n",
    "data_trg = [[line] for line in load_and_split('other/translations/test-target.de.txt')]\n",
    "data_pred = load_and_split('other/translations/test-pred.de.txt')\n",
    "data_pred_r = load_and_split('other/translations/test-pred-r.de.txt')\n",
    "data_gnmt = load_and_split('other/translations/test-gnmt.de.txt')\n",
    "\n",
    "data = list(zip(data_src, data_trg, data_pred, data_pred_r, data_gnmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limits = [5, 10, 15, 25, 50, 75, 100]\n",
    "bleus_pred = []\n",
    "bleus_gnmt = []\n",
    "\n",
    "for limit in limits:\n",
    "    trg, prd, gnmt = zip(*[triple for triple in zip(data_trg, data_pred, data_gnmt) if len(triple[0][0]) <= limit])\n",
    "    bleu_pred = 100*bleu.corpus_bleu(trg, prd, weights=(0.33,0.33,0.33))\n",
    "    bleu_gnmt = 100*bleu.corpus_bleu(trg, gnmt, weights=(0.33,0.33,0.33))\n",
    "    \n",
    "    bleus_pred.append(bleu_pred)\n",
    "    bleus_gnmt.append(bleu_gnmt)\n",
    "\n",
    "    print 'limit {} - bleu pred {} - bleu gnmt {}'.format(limit, bleu_pred, bleu_gnmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(limits, bleus_pred, label='IC')\n",
    "plt.plot(limits, bleus_gnmt, label='GT', alpha=0.8, linestyle='--')\n",
    "plt.title('BLEU score vs. length of translated text')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid()\n",
    "plt.savefig('mt-bleu-len.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered = [triple for triple in zip(data_src, data_trg, data_pred, data_gnmt) if len(triple[1][0]) <= 75]\n",
    "random.shuffle(filtered)\n",
    "src, trg, prd, gnmt = zip(*filtered)\n",
    "\n",
    "for ix in xrange(15):\n",
    "    print 'Src:', ' '.join(src[ix]).strip('\\n')\n",
    "    print 'Trg:', ' '.join(trg[ix][0]).strip('\\n')\n",
    "    print 'Prd:', ' '.join(prd[ix]).strip('\\n')\n",
    "    print 'Ggl:', ' '.join(gnmt[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
