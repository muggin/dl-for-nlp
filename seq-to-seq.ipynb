{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import codecs\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import tensorflow as tf\n",
    "import cPickle as pickle\n",
    "import scipy.sparse as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "from tensorflow.contrib.layers import safe_embedding_lookup_sparse\n",
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple, GRUCell\n",
    "\n",
    "from src.helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_corpus(file_path):\n",
    "    \"\"\" Load corpus from text file and tokenize \"\"\"\n",
    "    corpus = []\n",
    "    vocab_cnt = Counter()\n",
    "    tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    \n",
    "    with codecs.open(file_path, 'r', encoding='utf-8') as fd:\n",
    "        for line in fd:\n",
    "            # clean lines from any punctuation characters\n",
    "            clean_line = re.sub('[\\+\\-\\.\\,\\:\\;\\\"\\?\\!\\>\\<\\=\\(\\)\\n]+', '', line)\n",
    "            tokens = tokenizer.tokenize(clean_line.lower())\n",
    "            corpus.append(tokens)\n",
    "            vocab_cnt.update(tokens)\n",
    "            \n",
    "    return corpus, vocab_cnt\n",
    "\n",
    "\n",
    "def code_tokens(vocab_cnt, max_size=30000, unk_symbol='<unk>'):\n",
    "    \"\"\" Filter vocabulary and encode tokens \"\"\"\n",
    "    vocab = ['<pad>', '<sos>', '<eos>', '<unk>']\n",
    "    vocab.extend([word for word, _ in vocab_cnt.most_common(max_size)])\n",
    "    vocab_enc = {token: ix for ix, token in enumerate(vocab)}\n",
    "    vocab_dec = {ix: token for token, ix in vocab_enc.iteritems()}\n",
    "    \n",
    "    return vocab, vocab_enc, vocab_dec\n",
    "\n",
    "\n",
    "def generate_context_data(corpus, max_window_size=5, skip_size=1, flatten=True):\n",
    "    \"\"\" Generate data with context in format (target, [contexts]) or (target, context) \"\"\"\n",
    "    for center_ix in xrange(max_window_size, len(corpus)-max_window_size, skip_size):\n",
    "        # sample a window size for the given center word\n",
    "        window_size = np.random.randint(max_window_size) + 1\n",
    "        full_context = corpus[center_ix-window_size:center_ix] + corpus[center_ix+1: center_ix+window_size+1]\n",
    "        \n",
    "        if flatten:\n",
    "            for context_ix in xrange(2*window_size):\n",
    "                yield (corpus[center_ix], full_context[context_ix])\n",
    "        else:\n",
    "            yield(corpus[center_ix], full_context)\n",
    "\n",
    "\n",
    "def pad_data(data_arr, append_pre=[], append_suf=[], max_length=None):\n",
    "    \"\"\" Pad sequences to length of longest sequence in batch. Possibly append or prepend tokens \"\"\"\n",
    "    data_arr = [append_pre + row + append_suf for row in data_arr]\n",
    "    lengths = [len(row) for row in data_arr]\n",
    "    max_len = max(lengths) if not max_length else max_length\n",
    "    return np.array([row+[0]*(max_len-length) for row, length in zip(data_arr, lengths)]), lengths\n",
    "    \n",
    "                \n",
    "def batchify_data(data_generator, batch_size):\n",
    "    \"\"\" Split dataset (generator) into batches \"\"\"\n",
    "    if isinstance(data_generator, list):\n",
    "        for ix in xrange(0, len(data_generator), batch_size):\n",
    "            buff = data_generator[ix:ix+batch_size]\n",
    "            yield buff\n",
    "    else:\n",
    "        while data_generator:\n",
    "            buff = []\n",
    "            for ix in xrange(0, batch_size):\n",
    "                buff.append(next(data_generator))\n",
    "            yield buff\n",
    "            \n",
    "            \n",
    "def toy_data_generator(vocab_size, data_size, max_seq_length, reserved_digits=3):\n",
    "    \"\"\" Generate toy data of integers up to Vocab Size \"\"\"\n",
    "    for _ in xrange(data_size):\n",
    "        seq_length = np.random.randint(max_seq_length) + 1\n",
    "        output = [np.random.randint(vocab_size-reserved_digits)+reserved_digits for _ in xrange(seq_length)]\n",
    "        yield (output, output)\n",
    "\n",
    "\n",
    "def save_embeddings(embeddings_obj, file_name):\n",
    "    \"\"\" Save word embeddings and helper structures \"\"\"\n",
    "    with open(file_name, 'wb') as fd:\n",
    "        pickle.dump(embeddings_obj, fd)\n",
    "    \n",
    "\n",
    "def load_embeddings(file_name):\n",
    "    \"\"\" Load word embeddings and helper structures \"\"\"\n",
    "    with open(file_name, 'r') as fd:\n",
    "        embeddings_obj = pickle.load(fd)\n",
    "    return embeddings_obj\n",
    "    \n",
    "    \n",
    "def get_tsne_embeddings(embedding_matrix):\n",
    "    \"\"\" Compute t-SNE representation of embeddings \"\"\"\n",
    "    tsne = TSNE(perplexity=25, n_components=2, init='pca', n_iter=5000)\n",
    "    return tsne.fit_transform(embedding_matrix)\n",
    "\n",
    "\n",
    "def get_pca_embeddings(embedding_matrix):\n",
    "    \"\"\" Compute PCA representation of embeddings \"\"\"\n",
    "    pca = PCA(n_components=2)\n",
    "    return pca.fit_transform(embedding_matrix)\n",
    "\n",
    "\n",
    "def plot_embeddings(embeddings, words=[], words_cnt=500, method='pca', figsize=(8,8)):\n",
    "    \"\"\" Plot subset of embeddings in 2D space using t-SNE or PCA \"\"\"\n",
    "    embedding_matrix = embeddings._embeddings\n",
    "    vocab_dec = embeddings._vocab_dec\n",
    "    vocab_enc = embeddings._vocab_enc\n",
    "    \n",
    "    # prepare data\n",
    "    if not words:\n",
    "        vocab_size = embedding_matrix.shape[0]\n",
    "        ixs = range(vocab_size)\n",
    "        random.shuffle(ixs)\n",
    "        chosen_ixs = ixs[:words_cnt]\n",
    "        labels = [vocab_dec[ix] for ix in chosen_ixs]\n",
    "        word_vecs = embedding_matrix[chosen_ixs]\n",
    "    else:\n",
    "        labels = words\n",
    "        chosen_ixs = [vocab_enc[word] for word in words]\n",
    "        word_vecs = embedding_matrix[chosen_ixs]\n",
    "        \n",
    "    if method == 'tsne':\n",
    "        low_dim_embeddings = get_tsne_embeddings(word_vecs)\n",
    "    else:\n",
    "        low_dim_embeddings = get_pca_embeddings(word_vecs)\n",
    "        \n",
    "    # plot reduced vectors\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    for embedding, label in zip(low_dim_embeddings, labels):\n",
    "        x, y = embedding[0], embedding[1]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label, xy=(x, y), xytext=(5, 2), \n",
    "                     textcoords='offset points', ha='right', \n",
    "                     va='bottom')\n",
    "    plt.yticks=[]\n",
    "    plt.xticks=[]\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "class Embeddings(object):\n",
    "    \"\"\" Class wrapping word embeddings \"\"\"\n",
    "    def __init__(self, embedding_matrix, vocab_enc, vocab_dec):\n",
    "        self._embeddings = embedding_matrix\n",
    "        self._vocab_enc = vocab_enc\n",
    "        self._vocab_dec = vocab_dec\n",
    "    \n",
    "    def find_embedding(self, word):\n",
    "        \"\"\" Find embedding for a given word \"\"\"\n",
    "        if isinstance(word, str):\n",
    "            word = self._vocab_enc[word]\n",
    "        return self._embeddings[word]\n",
    "    \n",
    "    def find_neighbors(self, word, k=5, nearest=True, exclude=[], include_scores=False):\n",
    "        \"\"\" Find neighboring words (semantic regularities) \"\"\"\n",
    "        word_ix = self._vocab_enc[word]\n",
    "        exclude = exclude + [word_ix]\n",
    "        \n",
    "        # find neighbors\n",
    "        word_emb = self._embeddings[word_ix]\n",
    "        similarities = self._embeddings.dot(word_emb)\n",
    "        similarities[exclude] = 0\n",
    "        best_matches = np.argsort(similarities)\n",
    "        trimmed_matches = best_matches[-k:][::-1] if nearest else best_matches[:k]\n",
    "        return [(self._vocab_dec[word_ix], similarities[word_ix]) for word_ix in trimmed_matches]\n",
    "    \n",
    "    def find_analogous(self, word_a, word_b, word_c, k=5):\n",
    "        \"\"\" Find analogous word (syntactic regularities: word_a - word_b = x - word_c) \"\"\"\n",
    "        word_a_ix, word_b_ix, word_c_ix = [self._vocab_enc[word] for word in [word_a, word_b, word_c]]\n",
    "        exclude = [word_a_ix, word_b_ix, word_c_ix]\n",
    "        \n",
    "        emb_a = self.find_embedding(word_a_ix) \n",
    "        emb_b = self.find_embedding(word_b_ix) \n",
    "        emb_c = self.find_embedding(word_c_ix) \n",
    "        emb_d_hat = emb_a - emb_b + emb_c\n",
    "        similarities = self._embeddings.dot(emb_d_hat)\n",
    "        similarities[exclude] = 0\n",
    "        best_matches = np.argsort(similarities)\n",
    "        trimmed_matches = best_matches[-k:][::-1]\n",
    "        return [(self._vocab_dec[word_ix], similarities[word_ix]) for word_ix in trimmed_matches]\n",
    "    \n",
    "    def vocab(self):\n",
    "        \"\"\" Return vocabulary list \"\"\"\n",
    "        return self._vocab_enc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus A size (total tokens): 177655\n",
      "Corpus A vocabulary size (distinct tokens): 23614\n",
      "Most popular words (corpus A): [(u'w', 6558), (u'i', 5091), (u'na', 3013), (u'z', 2633), (u'\\u017ce', 2189)]\n",
      "\n",
      "Corpus B size (total tokens): 209813\n",
      "Corpus B vocabulary size (distinct tokens): 11012\n",
      "Most popular words (corpus B): [(u'the', 15602), (u'of', 8042), (u'to', 6611), (u'and', 6587), (u'in', 4925)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAEYCAYAAABBWFftAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1200b3750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CORPUS_A_PATH, CORPUS_B_PATH = './corpora/europarl.de-en.de', './corpora/europarl.de-en.en'\n",
    "CORPUS_A_PATH, CORPUS_B_PATH = './corpora/europarl.pl-en.pls', './corpora/europarl.pl-en.ens'\n",
    "\n",
    "# LOAD CORPUS\n",
    "corpus_a, vocab_cnt_a = load_corpus(CORPUS_A_PATH)\n",
    "corpus_b, vocab_cnt_b = load_corpus(CORPUS_B_PATH)\n",
    "\n",
    "raw_corpus_a_size = sum(vocab_cnt_a.itervalues())\n",
    "raw_vocab_a_size = len(vocab_cnt_a)\n",
    "raw_corpus_b_size = sum(vocab_cnt_b.itervalues())\n",
    "raw_vocab_b_size = len(vocab_cnt_b)\n",
    "\n",
    "print 'Corpus A size (total tokens):', raw_corpus_a_size\n",
    "print 'Corpus A vocabulary size (distinct tokens):', raw_vocab_a_size\n",
    "print 'Most popular words (corpus A):', vocab_cnt_a.most_common(5)\n",
    "print\n",
    "print 'Corpus B size (total tokens):', raw_corpus_b_size\n",
    "print 'Corpus B vocabulary size (distinct tokens):', raw_vocab_b_size\n",
    "print 'Most popular words (corpus B):', vocab_cnt_b.most_common(5)\n",
    "\n",
    "# visualize distribution\n",
    "counts_a = sorted(vocab_cnt_a.itervalues(), reverse=True)\n",
    "counts_b = sorted(vocab_cnt_b.itervalues(), reverse=True)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)\n",
    "plt.semilogy(range(len(counts_a)), counts_a)\n",
    "plt.title('Distribution of token occurences (Corpus SRC)')\n",
    "plt.xlabel('Token')\n",
    "plt.ylabel('Occurences')\n",
    "plt.grid()\n",
    "plt.subplot(122)\n",
    "plt.semilogy(range(len(counts_b)), counts_b)\n",
    "plt.title('Distribution of token occurences (Corpus TRG)')\n",
    "plt.xlabel('Token')\n",
    "plt.ylabel('Occurences')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean corpus A size (total sentences): 10000\n",
      "Clean corpus A vocabulary size (distinct tokens): 23618\n",
      "\n",
      "Clean corpus B size (total sentences): 10000\n",
      "Clean corpus B vocabulary size (distinct tokens): 11016\n"
     ]
    }
   ],
   "source": [
    "# LIMIT VOCABS\n",
    "LANG_A_TOKEN_LIMIT = 45000\n",
    "vocab_a, vocab_enc_a, vocab_dec_a = code_tokens(vocab_cnt_a, LANG_A_TOKEN_LIMIT)\n",
    "corpus_a_enc = [[vocab_enc_a[word] for word in sentence if word in vocab_enc_a] for sentence in corpus_a]\n",
    "\n",
    "LANG_B_TOKEN_LIMIT = 25000\n",
    "vocab_b, vocab_enc_b, vocab_dec_b = code_tokens(vocab_cnt_b, LANG_B_TOKEN_LIMIT)\n",
    "corpus_b_enc = [[vocab_enc_b[word] for word in sentence if word in vocab_enc_b] for sentence in corpus_b]\n",
    "\n",
    "print 'Clean corpus A size (total sentences):', len(corpus_a_enc)\n",
    "print 'Clean corpus A vocabulary size (distinct tokens):', len(vocab_a)\n",
    "print\n",
    "print 'Clean corpus B size (total sentences):', len(corpus_b_enc)\n",
    "print 'Clean corpus B vocabulary size (distinct tokens):', len(vocab_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_par = zip(corpus_a_enc, corpus_b_enc)\n",
    "length_diff = Counter([abs(len(a) - len(b)) for a, b in corpus_par])\n",
    "\n",
    "print 'Max length diff:', max(length_diff.keys())\n",
    "print 'Avg length diff:', sum(length_diff.keys()) / len(corpus_par)\n",
    "\n",
    "keys, values = zip(*sorted(length_diff.iteritems(), key=lambda x: x[0]))\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.semilogy(keys, values)\n",
    "plt.title('Distribution of length differences (Corpus Parallel)')\n",
    "plt.xlabel('Length Difference')\n",
    "plt.ylabel('Occurences')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeqToSeq(object):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, emb_size=100, enc_units=100, dec_units=100, \n",
    "                 num_layers=1, bi_dir=False, learning_rate=1e-3, pad_token=0, eos_token=2):\n",
    "        self.src_vocab_size = src_vocab_size\n",
    "        self.trg_vocab_size = trg_vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        self.enc_units = enc_units\n",
    "        self.dec_units = dec_units\n",
    "        self.num_layers = num_layers\n",
    "        self.bi_dir = bi_dir\n",
    "        self.learning_rate = learning_rate\n",
    "        self.pad_token = pad_token\n",
    "        self.eos_token = eos_token\n",
    "        \n",
    "        self._build_model()\n",
    "        \n",
    "    def _init_placeholders(self):\n",
    "        with tf.variable_scope('placeholders') as scope:\n",
    "            self.enc_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "            self.dec_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_inputs')\n",
    "            self.dec_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "\n",
    "            self.enc_inputs_len = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_len')\n",
    "            self.dec_inputs_len = tf.placeholder(shape=(None,), dtype=tf.int32, name='decoder_inputs_len')\n",
    "            self.max_dec_inputs_len = tf.reduce_max(self.dec_inputs_len, name='max_decoder_inputs_len')\n",
    "            \n",
    "            self.avg_eval_loss = tf.placeholder_with_default(0.0, shape=None, name='avg_eval_loss')\n",
    "            \n",
    "    def _init_variables(self):\n",
    "        # define global variables\n",
    "        self.global_step = tf.Variable(\n",
    "            initial_value=0, \n",
    "            trainable=False, \n",
    "            name='global_step')\n",
    "        \n",
    "        # define embeddings and lookup\n",
    "        with tf.variable_scope('embeddings') as scope:\n",
    "            self.embeddings_src = tf.Variable(\n",
    "                tf.random_uniform([self.src_vocab_size, self.emb_size], -0.25, 0.25), \n",
    "                dtype=tf.float32,\n",
    "                name='embeddings_src')\n",
    "            self.embeddings_trg = tf.Variable(\n",
    "                tf.random_uniform([self.trg_vocab_size, self.emb_size], -0.25, 0.25), \n",
    "                dtype=tf.float32,\n",
    "                name='embeddings_trg')\n",
    "    \n",
    "    def _init_encoder(self):\n",
    "        with tf.variable_scope('encoder') as scope:\n",
    "            enc_inputs_emb = tf.nn.embedding_lookup(self.embeddings_src, self.enc_inputs)\n",
    "            enc_cell = tf.contrib.rnn.GRUCell(self.enc_units)\n",
    "            _, self.enc_final_state = tf.nn.dynamic_rnn(\n",
    "                cell=enc_cell, \n",
    "                inputs=enc_inputs_emb, \n",
    "                sequence_length=self.enc_inputs_len, \n",
    "                time_major=False, \n",
    "                dtype=tf.float32, \n",
    "                scope='encoder_cell')\n",
    "        \n",
    "    def _init_decoder(self):\n",
    "        # training decoder\n",
    "        with tf.variable_scope('decoder') as scope:\n",
    "            dec_inputs_emb = tf.nn.embedding_lookup(self.embeddings_trg, self.dec_inputs)\n",
    "            dec_out_layer = layers_core.Dense(self.trg_vocab_size)\n",
    "            dec_cell = tf.contrib.rnn.GRUCell(self.dec_units)\n",
    "\n",
    "            dec_train_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                inputs=dec_inputs_emb,\n",
    "                sequence_length=self.dec_inputs_len,\n",
    "                time_major=False,\n",
    "                name='training_helper')\n",
    "\n",
    "            dec_train_decoder = seq2seq.BasicDecoder(\n",
    "                cell=dec_cell,\n",
    "                helper=dec_train_helper,\n",
    "                initial_state=self.enc_final_state,\n",
    "                output_layer=dec_out_layer)\n",
    "\n",
    "            self.dec_train_outputs = seq2seq.dynamic_decode(\n",
    "                decoder=dec_train_decoder,\n",
    "                output_time_major=False,\n",
    "                impute_finished=True,\n",
    "                maximum_iterations=self.max_dec_inputs_len)[0]\n",
    "            \n",
    "            # inference decoder\n",
    "            batch_size = tf.shape(self.enc_inputs)[0]\n",
    "            eos_slice = tf.fill([batch_size], self.eos_token, name='EOS')\n",
    "\n",
    "            dec_infer_helper = seq2seq.GreedyEmbeddingHelper(\n",
    "                embedding=self.embeddings_trg,\n",
    "                start_tokens=eos_slice,\n",
    "                end_token=self.eos_token)\n",
    "\n",
    "            dec_infer_decoder = seq2seq.BasicDecoder(\n",
    "                cell=dec_cell,\n",
    "                helper=dec_infer_helper,\n",
    "                initial_state=self.enc_final_state,\n",
    "                output_layer=dec_out_layer)\n",
    "\n",
    "            self.dec_infer_outputs = seq2seq.dynamic_decode(\n",
    "                decoder=dec_infer_decoder,\n",
    "                output_time_major=False,\n",
    "                impute_finished=True)[0]\n",
    "    \n",
    "    def _init_optimizer(self):\n",
    "        with tf.variable_scope('optimization') as scope:\n",
    "            dec_train_logits = tf.identity(self.dec_train_outputs.rnn_output)\n",
    "            dec_infer_logits = tf.identity(self.dec_infer_outputs.rnn_output)\n",
    "            self.dec_train_preds = self.dec_train_outputs.sample_id \n",
    "            self.dec_infer_preds = self.dec_infer_outputs.sample_id\n",
    "\n",
    "            masks = tf.sequence_mask(\n",
    "                lengths=self.dec_inputs_len, \n",
    "                maxlen=self.max_dec_inputs_len,\n",
    "                dtype=tf.float32, \n",
    "                name='masks')\n",
    "\n",
    "            self.loss = seq2seq.sequence_loss(\n",
    "                logits=dec_train_logits,\n",
    "                targets=self.dec_targets,\n",
    "                weights=masks,\n",
    "                average_across_timesteps=True,\n",
    "                average_across_batch=True)\n",
    "\n",
    "            # setup optimizer and training step\n",
    "            self.opt = tf.train.AdamOptimizer(self.learning_rate)\n",
    "            \n",
    "            trainable_params = tf.trainable_variables()\n",
    "            gradients = tf.gradients(self.loss, trainable_params)\n",
    "            # add gradient clipping\n",
    "            clip_gradients = gradients\n",
    "            self.updates = self.opt.apply_gradients(\n",
    "                zip(clip_gradients, trainable_params), \n",
    "                global_step=self.global_step)\n",
    "    \n",
    "            # summaries\n",
    "            self.train_summary = tf.summary.scalar('train_loss', self.loss)\n",
    "            self.valid_summary = tf.summary.scalar('valid_loss', self.loss)\n",
    "            self.avg_valid_summary = tf.summary.scalar('avg_valid_loss', self.avg_eval_loss)\n",
    "            \n",
    "    def _build_model(self):\n",
    "        self._init_placeholders()\n",
    "        self._init_variables()\n",
    "        self._init_encoder()\n",
    "        self._init_decoder()\n",
    "        self._init_optimizer()\n",
    "        \n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    def _get_feed_dict(self, enc_in, enc_in_len, dec_in=None, dec_in_len=None, dec_out=None):\n",
    "            feed_dict = { self.enc_inputs: enc_in, self.enc_inputs_len: enc_in_len}\n",
    "            \n",
    "            if dec_in is not None:\n",
    "                feed_dict[self.dec_inputs] = dec_in\n",
    "            if dec_in_len is not None:\n",
    "                feed_dict[self.dec_inputs_len] = dec_in_len\n",
    "            if dec_out is not None:\n",
    "                feed_dict[self.dec_targets] = dec_out\n",
    "                \n",
    "            return feed_dict\n",
    "    \n",
    "    def train(self, sess, enc_inputs, enc_inputs_len, dec_inputs, dec_inputs_len, dec_targets):\n",
    "        fd = self._get_feed_dict(enc_inputs, enc_inputs_len, \n",
    "                                 dec_inputs, dec_inputs_len, \n",
    "                                 dec_targets)\n",
    "        \n",
    "        operations = [self.updates, self.loss, self.train_summary, self.enc_final_state]\n",
    "        _, l, s, e = sess.run(operations, fd)\n",
    "        return l, s, e\n",
    "    \n",
    "    def evaluate(self, sess, enc_inputs, enc_inputs_len, dec_inputs, dec_inputs_len, dec_targets):\n",
    "        fd = self._get_feed_dict(enc_inputs, enc_inputs_len, \n",
    "                                 dec_inputs, dec_inputs_len, \n",
    "                                 dec_targets)\n",
    "        \n",
    "        operations = [self.loss, self.valid_summary, self.dec_train_preds, self.enc_final_state]\n",
    "        l, s, p, e = sess.run(operations, fd)\n",
    "        return l, s, p, e\n",
    "    \n",
    "    def infer(self, sess, enc_inputs, enc_inputs_len):\n",
    "        fd = self._get_feed_dict(enc_inputs, enc_inputs_len)\n",
    "        return sess.run([self.dec_infer_preds], fd)\n",
    "    \n",
    "    def encode_seq(self, sess, enc_inputs, enc_inputs_len):\n",
    "        fd = self._get_feed_dict(enc_inputs, enc_inputs_len)\n",
    "        return sess.run([self.enc_final_state], fd)\n",
    "    \n",
    "    def save_model(self, sess, path):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, save_path=path, global_step=self.global_step)\n",
    "    \n",
    "    def restore_model(self, sess, path):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example - Reconstructing Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT PARAMETERS\n",
    "VOCAB_SIZE = 10\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_DATA_SIZE = 500000\n",
    "VAL_DATA_SIZE = 500\n",
    "\n",
    "NUM_LAYERS = 1\n",
    "EMB_SIZE = 20\n",
    "ENC_UNITS = 20\n",
    "DEC_UNITS = ENC_UNITS\n",
    "LEARNING_RATE = 0.001\n",
    "HARD_MAX_LEN = 128\n",
    "\n",
    "SUMM_INTERVAL = 100\n",
    "EVAL_INTERVAL = 250\n",
    "CKPT_INTERVAL = 1000\n",
    "\n",
    "CKPT_PATH = './models/'\n",
    "LOG_PATH = './logs/'\n",
    "EXPERIMENT_NAME = 'toy-example'\n",
    "\n",
    "# EXPERIMENT DATA\n",
    "train_data = toy_data_generator(VOCAB_SIZE, TRAIN_DATA_SIZE, 15, 3)\n",
    "eval_data = list(toy_data_generator(VOCAB_SIZE, VAL_DATA_SIZE, 15, 3))\n",
    "vocab_dec_a = {ix: str(ix) for ix in xrange(11)}\n",
    "vocab_dec_b = vocab_dec_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Europarl DE-EN Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT PARAMETERS\n",
    "VOCAB_SIZE_SRC = len(vocab_a)\n",
    "VOCAB_SIZE_TRG = len(vocab_b)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "NUM_LAYERS = 1\n",
    "EMB_SIZE = 100\n",
    "ENC_UNITS = 200\n",
    "DEC_UNITS = ENC_HIDDEN_UNITS\n",
    "LEARNING_RATE = 0.001\n",
    "HARD_MAX_LEN = 128\n",
    "\n",
    "SUMM_INTERVAL = 100\n",
    "EVAL_INTERVAL = 250\n",
    "CKPT_INTERVAL = 1000\n",
    "\n",
    "CKPT_PATH = './models/'\n",
    "LOG_PATH = './logs/'\n",
    "EXPERIMENT_NAME = 'ep-de'\n",
    "\n",
    "# EXPERIMENT DATA\n",
    "train_split, eval_split, test_split = 0.8, 0.1, 0.1\n",
    "random.seed(1)\n",
    "random.shuffle(corpora)\n",
    "train_data = pass\n",
    "eval_data = pass\n",
    "test_data = pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = SeqToSeq(VOCAB_SIZE, VOCAB_SIZE, EMB_SIZE, ENC_UNITS, DEC_UNITS, learning_rate=LEARNING_RATE)\n",
    "\n",
    "try:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    summary_writer = tf.summary.FileWriter(\n",
    "        os.path.join(LOG_PATH, EXPERIMENT_NAME + time.strftime(\"%Y-%m-%d-%H-%M-%S\")),\n",
    "        graph=sess.graph)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        batches_gen = batchify_data(train_data, BATCH_SIZE)\n",
    "        train_losses = []\n",
    "        for data_batch in batches_gen: \n",
    "            batch_src, batch_trg = zip(*data_batch)\n",
    "            \n",
    "            # prepare batch\n",
    "            enc_inp, enc_lengths = pad_data(batch_src, append_suf=[2])\n",
    "            dec_inp, _ = pad_data(batch_trg, append_pre=[2])\n",
    "            dec_trg, dec_lengths = pad_data(batch_trg, append_suf=[2])\n",
    "            \n",
    "            # training step\n",
    "            if enc_inp.shape[1] > HARD_MAX_LEN: continue\n",
    "            l, s, _ = model.train(sess, enc_inp, enc_lengths, dec_inp, dec_lengths, dec_trg)\n",
    "            train_losses.append(l)\n",
    "            \n",
    "            # summarize, eval, etc.\n",
    "            global_step = model.global_step.eval()\n",
    "            \n",
    "            if global_step % CKPT_INTERVAL == 0:\n",
    "                ckpt_file = os.path.join(CKPT_PATH, EXPERIMENT_NAME + time.strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "                model.save_model(sess, ckpt_file)\n",
    "                print 'Saved model...'\n",
    "                \n",
    "            if global_step == 1 or global_step % SUMM_INTERVAL == 0:\n",
    "                summary_writer.add_summary(s, global_step)\n",
    "\n",
    "            if global_step == 1 or global_step % EVAL_INTERVAL == 0:\n",
    "                eval_losses = []\n",
    "                for batch_data in batchify_data(eval_data, BATCH_SIZE): \n",
    "                    batch_src, batch_trg = zip(*data_batch)\n",
    "                    enc_inp, enc_lengths = pad_data(batch_src, append_suf=[2])\n",
    "                    dec_inp, _ = pad_data(batch_trg, append_pre=[2])\n",
    "                    dec_trg, dec_lengths = pad_data(batch_trg, append_suf=[2])\n",
    "                    l, _, p, _ = model.evaluate(sess, enc_inp, enc_lengths, dec_inp, dec_lengths, dec_trg)\n",
    "                    eval_losses.append(l)\n",
    "                    \n",
    "                eval_s = sess.run(model.avg_valid_summary, {model.avg_eval_loss: np.mean(eval_losses)})\n",
    "                summary_writer.add_summary(eval_s, global_step)\n",
    "                \n",
    "                print('batch {}'.format(global_step))\n",
    "                print('train losses: {} / eval losses: {}'.format(np.mean(train_losses), np.mean(eval_losses)))\n",
    "                for i, (inp, pred) in enumerate(zip(enc_inp, p)[:3]):\n",
    "                    print('sample {}:'.format(i + 1))\n",
    "                    print('input     >> {}'.format(' '.join([vocab_dec_a[word].encode('ascii', errors='replace') for word in inp])))\n",
    "                    print('predicted >> {}'.format(' '.join([vocab_dec_b[word].encode('ascii', errors='replace') for word in pred])))\n",
    "                    \n",
    "                # clear train losses\n",
    "                train_losses = []\n",
    "        summary_writer.flush()\n",
    "                    \n",
    "except KeyboardInterrupt:\n",
    "    model.save_model(sess, ckpt_file)\n",
    "    summary_writer.close()\n",
    "    print 'Training Interrupted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = [[3,4,6,8,9,2]]\n",
    "enc_inp, enc_lengths = pad_data(batch_data, append_suf=[2])\n",
    "print 'I >>', batch_data\n",
    "print 'O >>', model.infer(sess, enc_inp, enc_lengths)[0]\n",
    "\n",
    "batch_data = [[3,4,6,8,9], [3,4,6,8,8], [3,4,6,8,3], [5,5,5,6,7], [5,5,5,5,6,9], [2,2,2,2,4]]\n",
    "enc_inp, enc_lengths = pad_data(batch_data, append_suf=[2])\n",
    "data_enc = model.encode_seq(sess, enc_inp, enc_lengths)[0]\n",
    "data_enc = data_enc / np.linalg.norm(data_enc, axis=1, keepdims=True)\n",
    "print 'Similarites:', data_enc.dot(data_enc[0].T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
